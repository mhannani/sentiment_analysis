{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT models trained on 80% MAC dataset and evaluated on the full MYC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_finetuned_on_mac_results_on_myc = {\n",
    "    \"bert-base-multilingual-cased\": {\n",
    "        'checkpoint': \"bert-base-multilingual-cased/checkpoint-17185\",\n",
    "        'accuracy': 0.560163914069291, \n",
    "        'precision': 0.5944748608070536, \n",
    "        'recall': 0.576292962461424, \n",
    "        'f1': 0.5443771407643445\n",
    "    },\n",
    "    \"bert-base-arabic\": {\n",
    "        'checkpoint': \"bert-base-arabic/checkpoint-2946\",\n",
    "        'accuracy': 0.5807773500558798, \n",
    "        'precision': 0.6569261617927782, \n",
    "        'recall': 0.6023387712640138, \n",
    "        'f1': 0.5501892107367392\n",
    "    },\n",
    "    \"darijabert-arabizi\": {\n",
    "        'checkpoint': \"darijabert-arabizi/checkpoint-10311\",\n",
    "        'accuracy': 0.5828883645846269, \n",
    "        'precision': 0.6243462628947318, \n",
    "        'recall': 0.5994429172260548, \n",
    "        'f1': 0.5671833148678399\n",
    "    },\n",
    "    \"DarijaBERT\": {\n",
    "        'checkpoint': \"DarijaBERT/checkpoint-14239\",\n",
    "        'accuracy': 0.6189618775611573, \n",
    "        'precision': 0.6813790067106706, \n",
    "        'recall': 0.637299477516956, \n",
    "        'f1': 0.600870422702932\n",
    "    },\n",
    "    \"bert-base-arabertv2\": {\n",
    "        'checkpoint': \"bert-base-arabertv2/checkpoint-8347\",\n",
    "        'accuracy': 0.5995281261641624, \n",
    "        'precision': 0.6392264109667269, \n",
    "        'recall': 0.615076663780127, \n",
    "        'f1': 0.5868442368207847\n",
    "    }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
